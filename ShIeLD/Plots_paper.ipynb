{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "cwd = os.getcwd()\n",
    "from scipy.stats import mannwhitneyu\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tissue_type_name = ['normalLiver', 'core', 'rim']\n",
    "tissue_dict = {'normalLiver': 0,\n",
    "               'core': 1,\n",
    "               'rim': 2}\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "save_path = os.path.join(f'{cwd}','Plots_paper')\n",
    "os.system(f'mkdir -p {save_path}')\n",
    "from collections import Counter\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 36})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#there were conections that where very low on number <10 this threshould removes them from the calculation\n",
    "def mean_with_threshold(series, threshold):\n",
    "    if series.count() >= threshold:\n",
    "        return series.mean()\n",
    "    else:\n",
    "        return np.nan\n",
    "def median_with_threshold(series, threshold):\n",
    "    if series.count() >= threshold:\n",
    "        return series.median()\n",
    "    else:\n",
    "        return np.nan\n",
    "def std_with_threshold(series, threshold):\n",
    "    if series.count() >= threshold:\n",
    "        return series.std()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def mad_with_threshold(series, threshold):\n",
    "    if series.count() >= threshold:\n",
    "        return series.mad()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def sum_with_threshold(series, threshold):\n",
    "    if series.count() >= threshold:\n",
    "        return series.sum()\n",
    "    else:\n",
    "        return np.nan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def top_c2c_interaction(df,number_top):\n",
    "    flat = np.nan_to_num(df.values.flatten())\n",
    "    indices = np.argpartition(flat, -number_top)[-number_top:]\n",
    "    top_values = flat[indices]\n",
    "\n",
    "    # Convert these indices to row and column labels\n",
    "    cols, rows = np.unravel_index(indices, df.shape)\n",
    "    row_labels = df.index[rows]\n",
    "    col_labels = df.columns[cols]\n",
    "\n",
    "    # Create a result dataframe or list of tuples\n",
    "    top = pd.DataFrame({\n",
    "        'Column': row_labels,\n",
    "        'Row': col_labels,\n",
    "        'Value': top_values\n",
    "    })\n",
    "    return(top.sort_values(by='Value', ascending=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_steps_region_subsampleing = 100\n",
    "minimum_number_cells = 50\n",
    "similarity_measure = 'euclide'\n",
    "radius_neibourhood = 50\n",
    "\n",
    "input_dim = 27\n",
    "final_layer = 3\n",
    "batch_size = 450\n",
    "learning_rate = 1e-2\n",
    "number_attention_heads = 1\n",
    "concat_attentionheads = False\n",
    "data_set = 'train'\n",
    "\n",
    "comment = ''\n",
    "comment_norm = ''\n",
    "\n",
    "cell_types = ['B cells CD38+', 'B cells CD45RA', 'B cells PD-L1+',\n",
    "           'Granulocytes CD38+', 'Granulocytes CD38-', 'Kupffer cells',\n",
    "           'M2 Macrophages PD-L1+', 'M2 Macrophages PD-L1-', 'MAITs',\n",
    "           'MHCII APCs', 'Mixed Immune CD45+', 'NK Cells CD16',\n",
    "           'NK Cells CD56', 'T cells CD4', 'T cells CD4 PD-L1+',\n",
    "           'T cells CD4 naÃ¯ve', 'T cells CD57', 'T cells CD8 PD-1high',\n",
    "           'T cells CD8 PD-1low', 'T cells CD8 PD-L1+', 'Tregs']\n",
    "Top_interaction_number = 20\n",
    "\n",
    "attr_bool = False\n",
    "if attr_bool:\n",
    "    comment_att = '_attr'\n",
    "else:\n",
    "    comment_att = '_Noattr'\n",
    "\n",
    "f_final = 3\n",
    "Layer_1 = 27\n",
    "droup_out_rate = 0.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the phenotype to phenotype dictionary\n",
    "\n",
    "# Construct the name of the dictionary based on various parameters\n",
    "dict_name = f\"HL1_{Layer_1}_dp_{droup_out_rate}_r_{radius_neibourhood}_noSelfATT_{comment}_{minimum_number_cells}{comment_att}_eval_{data_set}\".replace(\n",
    "    '.', '_')\n",
    "\n",
    "# Print the dictionary name\n",
    "print(dict_name)\n",
    "\n",
    "# Construct the path to the pickle file containing the dictionary\n",
    "save_path = os.path.join(f'{cwd}','eval','baseline',f'{dict_name}.pkl')\n",
    "\n",
    "# Open the pickle file and load the dictionary\n",
    "with open(save_path, 'rb') as f:\n",
    "    \"\"\"\n",
    "    This block of code is responsible for loading a dictionary from a pickle file.\n",
    "    The name of the dictionary and the path to the pickle file are constructed based on various parameters.\n",
    "    The dictionary contains the true labels, predicted labels, normalized cell-to-cell attention matrices, IDs, and edge counts.\n",
    "    These values are extracted from the dictionary and converted to numpy arrays.\n",
    "    \"\"\"\n",
    "    dict_all = pickle.load(f)\n",
    "\n",
    "# Extract the true labels from the dictionary and convert to a numpy array\n",
    "true_labels_train = np.array(dict_all['true_labels_train'])\n",
    "\n",
    "# Extract the predicted labels from the dictionary and convert to a numpy array\n",
    "correct_predicted = np.array(dict_all['correct_predicted'])\n",
    "\n",
    "# Extract the IDs from the dictionary and convert to a numpy array\n",
    "ids_all = np.array(dict_all['ids_list'])\n",
    "\n",
    "# Extract the normalized cell-to-cell attention matrices from the dictionary\n",
    "cell_to_cell_mat_std = dict_all['normed_c2c_Att']\n",
    "\n",
    "# Extract the edge counts from the dictionary\n",
    "edge_count = dict_all['number_edges_c2c']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combine the whanted cells\n",
    "shortend_dfs = [df.drop(['T cells CD57','Kupffer cells'],axis=1).drop(['T cells CD57','Kupffer cells'],axis=0) for df in tqdm(cell_to_cell_mat_std)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calc liver top interaction\n",
    "\n",
    "tissue_id = tissue_dict['normalLiver']\n",
    "\n",
    "sample_id_list = true_labels_train == tissue_id\n",
    "\n",
    "all_dfs = list(compress(shortend_dfs, sample_id_list))\n",
    "print(len(all_dfs))\n",
    "threshould_liver = len(all_dfs)*0.01\n",
    "mean_cell_att_liver = pd.concat(all_dfs)\n",
    "df_liver = mean_cell_att_liver.groupby(mean_cell_att_liver.index).agg(lambda x: median_with_threshold(x, threshould_liver)).sort_index()[sorted(mean_cell_att_liver.columns)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_connections_liver = {}\n",
    "name_list_liver = []\n",
    "\n",
    "# Loop over each cell type\n",
    "for scr_cell in cell_types:\n",
    "    \"\"\"\n",
    "    This block of code is responsible for finding the top connections for each cell type in the liver.\n",
    "    It first gets the indices of the top connections for the source cell type.\n",
    "    If there are any top connections, it gets the values of these connections and appends them to a list.\n",
    "    It also appends the source cell type and destination cell type to another list.\n",
    "    It then adds the source cell type and its top connections to a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the indices of the top connections for the source cell type\n",
    "    top_dst_cells = df_liver[scr_cell][~np.isnan(df_liver[scr_cell])].sort_values(ascending=False)[:Top_interaction_number].index\n",
    "\n",
    "    values = []\n",
    "\n",
    "    # Loop over each top connection\n",
    "    for dst_cell in top_dst_cells:\n",
    "\n",
    "        # Append the value of the connection to the values list\n",
    "        values.append([dst_cell, mean_cell_att_liver[scr_cell][dst_cell]])\n",
    "\n",
    "        # Append the source cell type and destination cell type to the name list\n",
    "        name_list_liver.append([scr_cell, dst_cell])\n",
    "\n",
    "    # Add the source cell type and its top connections to the dictionary\n",
    "    top_connections_liver[scr_cell] = values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the alpha values for the Mann-Whitney U test\n",
    "alpha = 0.05\n",
    "alpha_plus = 0.005\n",
    "\n",
    "# Get the number of cell types\n",
    "number_cells = len(cell_types)\n",
    "\n",
    "# Create a subplot for each cell type\n",
    "fig, axs = plt.subplots(nrows=2, ncols=int(number_cells/2), figsize=(130,60), sharey=True, layout='constrained')\n",
    "\n",
    "# Set the line width and star size for the plot\n",
    "line_width = 5\n",
    "size_star = 2000\n",
    "\n",
    "# Loop over the rows and columns of the subplot\n",
    "for row in range(2):\n",
    "    for idx in range(int(number_cells/2)):\n",
    "\n",
    "        # Get the source cell type\n",
    "        scr_cell = cell_types[idx+int(number_cells/2)*row]\n",
    "\n",
    "        # Get the names and values of the top connections for the source cell type\n",
    "        names = [dst_cell[0] for dst_cell in top_connections_liver[scr_cell]]\n",
    "        values = [dst_cell[1][~np.isnan(dst_cell[1])] for dst_cell in top_connections_liver[scr_cell]\n",
    "                                                    if len(dst_cell[1])>2]\n",
    "\n",
    "        # Create a boxplot of the values\n",
    "        axs[row, idx].grid(True, linewidth=line_width)\n",
    "        box = axs[row, idx].boxplot(values)\n",
    "\n",
    "        # Set the line width for the boxplot\n",
    "        for element in ['boxes', 'whiskers', 'caps', 'medians', 'fliers']:\n",
    "            plt.setp(box[element], linewidth=line_width)\n",
    "\n",
    "        # Thicken subplot axis spines\n",
    "        for spine in axs[row, idx].spines.values():\n",
    "            spine.set_linewidth(line_width)\n",
    "\n",
    "        # Perform a Mann-Whitney U test for each destination cell type and mark significant results on the plot\n",
    "        for dst_cell_idx in range(len(names)):\n",
    "\n",
    "            # Get the data for the source cell type and the current destination cell type\n",
    "            data_1 = np.nan_to_num(df_liver[scr_cell].to_numpy())\n",
    "\n",
    "            # Perform the Mann-Whitney U test\n",
    "            stat, p = mannwhitneyu(data_1, np.nan_to_num(values[dst_cell_idx].to_numpy()))\n",
    "\n",
    "            # If the p-value is less than alpha, mark the result on the plot\n",
    "            if ((p < alpha) and (p > alpha_plus)):\n",
    "                marker = '*'\n",
    "                axs[row, idx].scatter(dst_cell_idx + 1, 1.05, marker=marker, color='black', s=size_star)\n",
    "            elif p < alpha_plus:\n",
    "                marker = '*'\n",
    "                axs[row, idx].scatter(dst_cell_idx + 1.1, 1.05, marker=marker, color='black', s=size_star)\n",
    "                axs[row, idx].scatter(dst_cell_idx + 0.9, 1.05, marker=marker, color='black', s=size_star)\n",
    "\n",
    "        # Set the x-ticks and title for the subplot\n",
    "        axs[row, idx].set_xticks(np.arange(1, Top_interaction_number+1), names, rotation=90)\n",
    "        axs[row, idx].grid(False)\n",
    "\n",
    "        # Calculate the median, lower quantile, and upper quantile for the source cell type\n",
    "        mat = np.nan_to_num(df_liver[scr_cell].to_numpy())\n",
    "        median = np.median(mat)\n",
    "        lower_quantile = np.quantile(mat, 0.25)\n",
    "        upper_quantile = np.quantile(mat, 0.75)\n",
    "\n",
    "        # Highlight the interquartile range and plot the median\n",
    "        axs[row, idx].axhspan(lower_quantile, upper_quantile, facecolor='green', alpha=0.2)\n",
    "        axs[row, idx].axhline(y=median, color='red', linestyle='--', linewidth=line_width)\n",
    "\n",
    "# Save the figure\n",
    "save_path = os.path.join(f'{cwd}', 'Plots_paper', 'liver_interactions.pdf')\n",
    "fig.savefig(save_path, dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Core"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the tissue ID for the core\n",
    "tissue_id = tissue_dict['core']\n",
    "\n",
    "# Create a list of boolean values indicating whether each sample in the training set is from the core\n",
    "sample_id_list = true_labels_train == tissue_id\n",
    "\n",
    "# Filter the list of dataframes to include only those from the core\n",
    "all_dfs = list(compress(shortend_dfs, sample_id_list))\n",
    "\n",
    "# Print the number of dataframes from the core\n",
    "print(len(all_dfs))\n",
    "\n",
    "# Calculate the threshold for the core as 1% of the number of dataframes from the core\n",
    "threshould_core = int(len(all_dfs)*0.01)\n",
    "\n",
    "# Concatenate all the dataframes from the core\n",
    "mean_cell_att_core = pd.concat(all_dfs)\n",
    "\n",
    "# Group the concatenated dataframe by index, calculate the median of each group with the threshold,\n",
    "# sort the dataframe by index, and select only the sorted columns\n",
    "df_core = mean_cell_att_core.groupby(mean_cell_att_core.index).agg(lambda x: median_with_threshold(x, threshould_core)).sort_index()[sorted(mean_cell_att_core.columns)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_connections_core = {}\n",
    "name_list_core = []\n",
    "# Loop over each cell type\n",
    "for scr_cell in cell_types:\n",
    "    \"\"\"\n",
    "    This block of code is responsible for finding the top connections for each cell type in the core.\n",
    "    It first gets the indices of the top connections for the source cell type.\n",
    "    If there are any top connections, it gets the values of these connections and appends them to a list.\n",
    "    It also appends the source cell type and destination cell type to another list.\n",
    "    It then adds the source cell type and its top connections to a dictionary.\n",
    "    If there are no top connections, it adds the source cell type and NaN to the dictionary.\n",
    "    \"\"\"\n",
    "    # Get the indices of the top connections for the source cell type\n",
    "    top_dst_cells = df_core[scr_cell][~np.isnan(df_core[scr_cell])].sort_values(ascending=False)[:Top_interaction_number].index\n",
    "\n",
    "    # If there are any top connections\n",
    "    if len(top_dst_cells) != 0:\n",
    "        values = []\n",
    "\n",
    "        # Loop over each top connection\n",
    "        for dst_cell in top_dst_cells:\n",
    "\n",
    "            # Append the source cell type and destination cell type to the name list\n",
    "            name_list_core.append([scr_cell, dst_cell])\n",
    "\n",
    "            # Append the value of the connection to the values list\n",
    "            values.append([dst_cell, mean_cell_att_core[scr_cell][dst_cell]])\n",
    "\n",
    "        # Add the source cell type and its top connections to the dictionary\n",
    "        top_connections_core[scr_cell] = values\n",
    "\n",
    "    # If there are no top connections\n",
    "    else:\n",
    "\n",
    "        # Add the source cell type and NaN to the dictionary\n",
    "        top_connections_core[scr_cell] = [np.nan]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the number of cell types\n",
    "number_cells = len(cell_types)\n",
    "\n",
    "# Create a subplot for each cell type\n",
    "fig, axs = plt.subplots(nrows=2, ncols=int(number_cells/2), figsize=(130,60), sharey=True, layout='constrained')\n",
    "\n",
    "# Set the line width and star size for the plot\n",
    "line_width = 5\n",
    "size_star = 2000\n",
    "\n",
    "# Loop over the rows and columns of the subplot\n",
    "for row in range(2):\n",
    "    for idx in range(int(number_cells/2)):\n",
    "\n",
    "        # Get the source cell type\n",
    "        scr_cell = cell_types[idx+int(number_cells/2)*row]\n",
    "\n",
    "        # If there are connections for the source cell type\n",
    "        if len(top_connections_core[scr_cell]) != 1 :\n",
    "\n",
    "            # Get the names of the top connections for the source cell type\n",
    "            names = [dst_cell[0] for dst_cell in top_connections_core[scr_cell]]\n",
    "\n",
    "            # Get the values of the top connections for the source cell type\n",
    "            values = []\n",
    "            for dst_cell in top_connections_core[scr_cell]:\n",
    "                if len(dst_cell[1])>2:\n",
    "                    values.append(dst_cell[1][~np.isnan(dst_cell[1])])\n",
    "                else:\n",
    "                    values.append([np.nan])\n",
    "\n",
    "            # Create a boxplot of the values\n",
    "            axs[row, idx].grid(True, linewidth=line_width)\n",
    "            box = axs[row,idx].boxplot(values)\n",
    "\n",
    "            # Set the line width for the boxplot\n",
    "            for element in ['boxes', 'whiskers', 'caps', 'medians', 'fliers']:\n",
    "                plt.setp(box[element], linewidth=line_width)\n",
    "\n",
    "            # Set the x-ticks for the subplot\n",
    "            axs[row,idx].set_xticks(np.arange(1,len(box['boxes'])+1),names,rotation=90)\n",
    "\n",
    "            # Remove grid lines\n",
    "            axs[row, idx].grid(False)\n",
    "\n",
    "            # Calculate the median, lower quantile, and upper quantile for the source cell type\n",
    "            mat = np.nan_to_num(df_core[scr_cell].to_numpy())\n",
    "            median = np.median(mat)\n",
    "            lower_quantile = np.quantile(mat, 0.25)\n",
    "            upper_quantile = np.quantile(mat, 0.75)\n",
    "\n",
    "            # Highlight the interquartile range and plot the median\n",
    "            axs[row, idx].axhspan(lower_quantile, upper_quantile, facecolor='green', alpha=0.2)\n",
    "            axs[row, idx].axhline(y=median, color='red', linestyle='--',linewidth=line_width)\n",
    "\n",
    "# Save the figure\n",
    "save_path = os.path.join(f'{cwd}','Plots_paper','core_interactions.pdf')\n",
    "fig.savefig(save_path,dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
